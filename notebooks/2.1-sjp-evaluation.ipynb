{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 - Model Evaluation\n",
    "\n",
    "In this notebook, we conduct baseline and enriched pipeline evaluation on the filtered dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# langchain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load environment variables\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_TYPE = os.environ[\"OPENAI_API_TYPE\"]\n",
    "OPENAI_API_VERSION = os.environ[\"OPENAI_API_VERSION\"]\n",
    "OPENAI_API_BASE = os.environ[\"OPENAI_API_BASE\"]\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "DEPLOYMENT_NAME = os.environ[\"DEPLOYMENT_NAME\"]\n",
    "MODEL_NAME = \"gpt-35-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "Load the filtered version of the Autocast dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data\"\n",
    "DATA_FILE_NAME = \"test_df_latest.json\"\n",
    "DATA_PATH = os.path.join(DATA_DIR, DATA_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_file_name(df, description=None):\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    df_size = df.shape[0]\n",
    "    file_name = f\"test_df-{current_time}-size_{df_size}\"\n",
    "    \n",
    "    if description is not None:\n",
    "        file_name += f\"-{description}\"\n",
    "    \n",
    "    file_ext = \".json\"\n",
    "    file_name += file_ext\n",
    "    \n",
    "    return file_name\n",
    "\n",
    "def save_test_df(df, file_name=None, data_dir=DATA_DIR, description=None):\n",
    "    if file_name is None:\n",
    "        file_name = build_file_name(df, description)\n",
    "    \n",
    "    file_path = os.path.join(data_dir, file_name)\n",
    "    \n",
    "    df.to_json(file_path, orient=\"records\", lines=True)\n",
    "    print(f\"Saved test dataframe to: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_json(DATA_PATH, orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataframe shape: (98, 27)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 98 entries, 0 to 97\n",
      "Data columns (total 27 columns):\n",
      " #   Column                          Non-Null Count  Dtype              \n",
      "---  ------                          --------------  -----              \n",
      " 0   question                        98 non-null     object             \n",
      " 1   id                              98 non-null     object             \n",
      " 2   background                      98 non-null     object             \n",
      " 3   publish_time                    98 non-null     datetime64[ns]     \n",
      " 4   close_time                      98 non-null     datetime64[ns, UTC]\n",
      " 5   tags                            98 non-null     object             \n",
      " 6   source_links                    98 non-null     object             \n",
      " 7   prediction_count                98 non-null     int64              \n",
      " 8   forecaster_count                98 non-null     int64              \n",
      " 9   answer                          0 non-null      float64            \n",
      " 10  choices                         98 non-null     object             \n",
      " 11  status                          98 non-null     object             \n",
      " 12  qtype                           98 non-null     object             \n",
      " 13  crowd                           98 non-null     object             \n",
      " 14  avg_pred                        98 non-null     float64            \n",
      " 15  median_pred                     98 non-null     float64            \n",
      " 16  majority_pred                   98 non-null     float64            \n",
      " 17  pred_taken                      98 non-null     float64            \n",
      " 18  acceptable_pred_lower_boundary  98 non-null     float64            \n",
      " 19  acceptable_pred_upper_boundary  98 non-null     float64            \n",
      " 20  context                         98 non-null     object             \n",
      " 21  examples                        98 non-null     object             \n",
      " 22  best_example                    98 non-null     object             \n",
      " 23  lowest_uncertainty              98 non-null     int64              \n",
      " 24  highest_uncertainty             98 non-null     float64            \n",
      " 25  average_uncertainty             98 non-null     float64            \n",
      " 26  external_context                98 non-null     object             \n",
      "dtypes: datetime64[ns, UTC](1), datetime64[ns](1), float64(9), int64(3), object(13)\n",
      "memory usage: 20.8+ KB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test dataframe shape: {test_df.shape}\")\n",
    "print(\"\")\n",
    "\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>id</th>\n",
       "      <th>background</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>close_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>source_links</th>\n",
       "      <th>prediction_count</th>\n",
       "      <th>forecaster_count</th>\n",
       "      <th>answer</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_taken</th>\n",
       "      <th>acceptable_pred_lower_boundary</th>\n",
       "      <th>acceptable_pred_upper_boundary</th>\n",
       "      <th>context</th>\n",
       "      <th>examples</th>\n",
       "      <th>best_example</th>\n",
       "      <th>lowest_uncertainty</th>\n",
       "      <th>highest_uncertainty</th>\n",
       "      <th>average_uncertainty</th>\n",
       "      <th>external_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Will there be a complex coordinated terrorist ...</td>\n",
       "      <td>G2124</td>\n",
       "      <td>CCTAs are a major concern for law enforcement ...</td>\n",
       "      <td>2021-09-17 15:49:41.402</td>\n",
       "      <td>2022-09-01 07:01:00+00:00</td>\n",
       "      <td>[Society, Security and Conflict]</td>\n",
       "      <td>[]</td>\n",
       "      <td>340</td>\n",
       "      <td>111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Entities:\\n- Complex coordinated terrorist att...</td>\n",
       "      <td>[{'example_question': 'Between 1 January 2018 ...</td>\n",
       "      <td>{'example_question': 'Will the government of C...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.082</td>\n",
       "      <td>The United States remains in a heightened thre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Before 1 September 2022, will Egypt, Ethiopia,...</td>\n",
       "      <td>G2125</td>\n",
       "      <td>Tensions between Egypt, Ethiopia, and Sudan co...</td>\n",
       "      <td>2021-09-17 15:49:44.237</td>\n",
       "      <td>2022-09-01 07:01:00+00:00</td>\n",
       "      <td>[Foreign Policy, Security and Conflict, Non-US...</td>\n",
       "      <td>[https://www.securitycouncilreport.org/whatsin...</td>\n",
       "      <td>166</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Entities:\\n- Egypt: a country in North Africa,...</td>\n",
       "      <td>[{'example_question': 'Will the EU amend its O...</td>\n",
       "      <td>{'example_question': 'Will either Turkey or Ru...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.104</td>\n",
       "      <td>As of August 2021, the foreign ministers of Eg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Before 1 January 2023, will the Taipei Economi...</td>\n",
       "      <td>G2141</td>\n",
       "      <td>Recent media reporting indicates discussions r...</td>\n",
       "      <td>2021-09-30 14:38:57.362</td>\n",
       "      <td>2023-01-01 08:01:00+00:00</td>\n",
       "      <td>[Foreign Policy, US Politics, Security and Con...</td>\n",
       "      <td>[]</td>\n",
       "      <td>188</td>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.36</td>\n",
       "      <td>Entities:\\n- Taipei Economic and Cultural Repr...</td>\n",
       "      <td>[{'example_question': 'Between 18 October and ...</td>\n",
       "      <td>{'example_question': 'Will the New START treat...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.040</td>\n",
       "      <td>The Taipei Economic and Cultural Representativ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question     id  \\\n",
       "0  Will there be a complex coordinated terrorist ...  G2124   \n",
       "1  Before 1 September 2022, will Egypt, Ethiopia,...  G2125   \n",
       "2  Before 1 January 2023, will the Taipei Economi...  G2141   \n",
       "\n",
       "                                          background            publish_time  \\\n",
       "0  CCTAs are a major concern for law enforcement ... 2021-09-17 15:49:41.402   \n",
       "1  Tensions between Egypt, Ethiopia, and Sudan co... 2021-09-17 15:49:44.237   \n",
       "2  Recent media reporting indicates discussions r... 2021-09-30 14:38:57.362   \n",
       "\n",
       "                 close_time  \\\n",
       "0 2022-09-01 07:01:00+00:00   \n",
       "1 2022-09-01 07:01:00+00:00   \n",
       "2 2023-01-01 08:01:00+00:00   \n",
       "\n",
       "                                                tags  \\\n",
       "0                   [Society, Security and Conflict]   \n",
       "1  [Foreign Policy, Security and Conflict, Non-US...   \n",
       "2  [Foreign Policy, US Politics, Security and Con...   \n",
       "\n",
       "                                        source_links  prediction_count  \\\n",
       "0                                                 []               340   \n",
       "1  [https://www.securitycouncilreport.org/whatsin...               166   \n",
       "2                                                 []               188   \n",
       "\n",
       "   forecaster_count  answer  ... pred_taken acceptable_pred_lower_boundary  \\\n",
       "0               111     NaN  ...       0.05                          -0.15   \n",
       "1                59     NaN  ...       0.05                          -0.15   \n",
       "2                51     NaN  ...       0.16                          -0.04   \n",
       "\n",
       "  acceptable_pred_upper_boundary  \\\n",
       "0                           0.25   \n",
       "1                           0.25   \n",
       "2                           0.36   \n",
       "\n",
       "                                             context  \\\n",
       "0  Entities:\\n- Complex coordinated terrorist att...   \n",
       "1  Entities:\\n- Egypt: a country in North Africa,...   \n",
       "2  Entities:\\n- Taipei Economic and Cultural Repr...   \n",
       "\n",
       "                                            examples  \\\n",
       "0  [{'example_question': 'Between 1 January 2018 ...   \n",
       "1  [{'example_question': 'Will the EU amend its O...   \n",
       "2  [{'example_question': 'Between 18 October and ...   \n",
       "\n",
       "                                        best_example  lowest_uncertainty  \\\n",
       "0  {'example_question': 'Will the government of C...                   0   \n",
       "1  {'example_question': 'Will either Turkey or Ru...                   0   \n",
       "2  {'example_question': 'Will the New START treat...                   0   \n",
       "\n",
       "   highest_uncertainty  average_uncertainty  \\\n",
       "0                 0.45                0.082   \n",
       "1                 0.50                0.104   \n",
       "2                 0.35                0.040   \n",
       "\n",
       "                                    external_context  \n",
       "0  The United States remains in a heightened thre...  \n",
       "1  As of August 2021, the foreign ministers of Eg...  \n",
       "2  The Taipei Economic and Cultural Representativ...  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sample_df(df, qtypes=[\"t/f\", \"mc\"], n=100):\n",
    "    \"\"\"\n",
    "    Build a sample dataframe with a fixed number of samples per question type.\n",
    "    \"\"\"\n",
    "    sample_df = pd.DataFrame()\n",
    "    for qtype in qtypes:\n",
    "        sample_df = pd.concat([sample_df, df[df[\"qtype\"] == qtype].sample(n=n, random_state=1)])\n",
    "    sample_df = sample_df.sample(frac=1, random_state=1)\n",
    "    return sample_df\n",
    "\n",
    "def filter_df_by_vals(df: pd.DataFrame, filter_dict: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters a dataframe based on a filter dictionary where the keys are dataframe\n",
    "    columns and the values are used to filter each column.\n",
    "\n",
    "    Args:\n",
    "        filter_dict (dict): filter dictionary\n",
    "        df (pd.DataFrame): dataframe\n",
    "    \"\"\"\n",
    "    df_filtered = df.copy()\n",
    "    for key, value in filter_dict.items():\n",
    "        df_filtered = df_filtered[df_filtered[key] == value]\n",
    "    return df_filtered\n",
    "\n",
    "def filter_df_by_tag(df: pd.DataFrame, tag_col: str, filter_tag: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters a dataframe based on whether filter_tag appears in the list of tags\n",
    "    located in tag_col.\n",
    "\n",
    "    Args:\n",
    "        tag_col (str): tag column\n",
    "        filter_tag (str): tag\n",
    "        df (pd.DataFrame): dataframe\n",
    "    \"\"\"\n",
    "    df_filtered = df.copy()\n",
    "    df_filtered = df_filtered[df_filtered[tag_col].apply(lambda x: filter_tag in x)]\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataframe has shape: (98, 27)\n"
     ]
    }
   ],
   "source": [
    "# filter df so qtype column is only t/f or mc\n",
    "test_df = test_df[test_df[\"qtype\"].isin([\"t/f\", \"mc\"])]\n",
    "\n",
    "# filter for active questions only\n",
    "test_df = test_df[test_df[\"status\"] == \"Active\"]\n",
    "test_df = test_df[test_df[\"choices\"].notna()]\n",
    "\n",
    "# drop duplicates\n",
    "test_df = test_df.drop_duplicates(subset=['id', 'question'])\n",
    "\n",
    "# print shape\n",
    "print(f\"Test dataframe has shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "\n",
    "We use Azure OpenAI services and a deployed GPT 3.5 chat completion model to generate predictions using a top K method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_results_data_name(df, model_name: str = MODEL_NAME,  description: str = None):\n",
    "    \"\"\"\n",
    "    Builds a name for the results data file.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): A dataframe with experiment results.\n",
    "        model_name (str): The name of the model.\n",
    "        description (str): A description of the results data.\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    df_size = df.shape[0]\n",
    "    \n",
    "    save_name = f\"{model_name}_{timestamp}_results-{df_size}\"\n",
    "    \n",
    "    if description is not None:\n",
    "        save_name += f\"_{description}\"\n",
    "\n",
    "    extension = \"json\"\n",
    "    save_name += f\".{extension}\"\n",
    "    \n",
    "    return save_name\n",
    "\n",
    "def save_results_data_json(df, model_name=MODEL_NAME, data_dir=\"../data\", save_path=None):\n",
    "    \"\"\"\n",
    "    Saves a results dataframe to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): A dataframe with experiment results.\n",
    "        model_name (str): The name of the model.\n",
    "        data_dir (str): The directory to save the JSON file to.\n",
    "        save_path (str): The path to save the JSON file to.\n",
    "    \"\"\"\n",
    "    if save_path is None:\n",
    "        save_name = build_results_data_name(df, model_name=model_name)\n",
    "        save_path = os.path.join(data_dir, save_name)\n",
    "        \n",
    "    df.to_json(save_path, orient=\"records\", indent=4)\n",
    "    print(f\"Saved results to: {save_path}\")\n",
    "\n",
    "def describe_question_row_by_idx(df, idx):\n",
    "    \"\"\"\n",
    "    Prints the question and choices for a given row in a dataframe.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): A dataframe of questions.\n",
    "        idx (int): The index of the row to describe.\n",
    "    \"\"\"\n",
    "    row = df.iloc[idx]\n",
    "    print(f\"Question:\\n{row['question']}\\n\")\n",
    "    \n",
    "    print(\"Choices:\")\n",
    "    for i, choice in enumerate(row[\"choices\"]):\n",
    "        print(f\"{chr(65 + i)} - {choice}\")\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"Crowd:\")\n",
    "    print(f\"Majority: {row['majority_pred']}\")\n",
    "    \n",
    "    lower_bound = row['acceptable_pred_lower_boundary']\n",
    "    upper_bound = row['acceptable_pred_upper_boundary']\n",
    "    print(f\"Acceptable range: ({round(lower_bound, 3)}, {round(upper_bound, 3)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Forecaster():\n",
    "    def __init__(self, chat, prompt: str):\n",
    "        \"\"\"\n",
    "        A class for forecasting answers to questions using a language model.\n",
    "\n",
    "        Args:\n",
    "            chat: A chat language model.\n",
    "            prompt (str): A prompt for the language model.\n",
    "        \"\"\"\n",
    "        self.chat = chat\n",
    "        self.prompt = prompt\n",
    "    \n",
    "    def format_choices(self, choices: list[str]):\n",
    "        \"\"\"\n",
    "        Accepts a list of choices and formats them for the language model\n",
    "        with a letter for each choice and one choice per line.\n",
    "\n",
    "        Args:\n",
    "            choices (list): A list of choices.\n",
    "        \"\"\"\n",
    "        formatted_choices = \"\\n\".join(\n",
    "            [f\"{chr(65 + idx)} - {choice}\" for idx, choice in enumerate(choices)]\n",
    "        )\n",
    "        return formatted_choices\n",
    "    \n",
    "    def valid_answer(self, answer: str):\n",
    "        \"\"\"\n",
    "        Returns True if the answer is valid, False otherwise.\n",
    "\n",
    "        Args:\n",
    "            answer (str): An answer.\n",
    "        \"\"\"\n",
    "        # invalid if answer is not a string or is None\n",
    "        if not isinstance(answer, str) or answer is None:\n",
    "            return False\n",
    "\n",
    "        # invalid if first character is not a letter\n",
    "        if not re.match(r\"[A-Z]\", answer[0]):\n",
    "            return False\n",
    "        \n",
    "        # invalid if second character is a letter\n",
    "        if len(answer) > 1 and re.match(r\"[A-Z]\", answer[1]):\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def clean_answer(self, answer: str):\n",
    "        \"\"\"\n",
    "        If the answer is valid, returns just the first letter of the answer.\n",
    "        Converts a yes/no answer to a letter, where yes is A and no is B.\n",
    "        Returns None if the answer is not valid.\n",
    "\n",
    "        Args:\n",
    "            answer (str): An answer.\n",
    "        \"\"\"\n",
    "        if not self.valid_answer(answer):\n",
    "            return None\n",
    "        \n",
    "        answer = self.yes_no_to_letter(answer)\n",
    "\n",
    "        return answer[0]\n",
    "    \n",
    "    def idx_from_letter(self, letter: str):\n",
    "        \"\"\"\n",
    "        Converts a letter (A, B, C, etc.) to an index, where A is 0, \n",
    "        B is 1, and so on. Returns None if the letter is not valid.\n",
    "\n",
    "        Args:\n",
    "            letter (str): A letter.\n",
    "        \"\"\"\n",
    "        if letter is None:\n",
    "            return None\n",
    "        \n",
    "        letter = letter.upper()\n",
    "        letter = letter.strip()\n",
    "        letter = re.sub(r\"[^A-Z]\", \"\", letter)\n",
    "\n",
    "        # return None if letter is not valid\n",
    "        if len(letter) != 1 or ord(letter) < 65 or ord(letter) > 90:\n",
    "            return None\n",
    "\n",
    "        return int(ord(letter) - 65)\n",
    "    \n",
    "    def yes_no_to_letter(self, answer: str):\n",
    "        \"\"\"\n",
    "        Converts a yes/no answer to a letter, where yes is A and no is B.\n",
    "\n",
    "        Args:\n",
    "            answer (str): A yes/no answer.\n",
    "        \"\"\"\n",
    "        if answer is None:\n",
    "            return answer\n",
    "        elif answer.lower() == \"yes\" or answer.lower() == \"y\":\n",
    "            return \"A\"\n",
    "        elif answer.lower() == \"no\" or answer.lower() == \"n\":\n",
    "            return \"B\"\n",
    "        else:\n",
    "            return answer\n",
    "        \n",
    "    def get_llm_response(self, vars: dict):\n",
    "        \"\"\"\n",
    "        Returns a response from the language model in the form of a dictionary\n",
    "        with the original prediction and the cleaned predicted answer.\n",
    "\n",
    "        Args:\n",
    "            vars (dict): A dictionary with the question and choices.\n",
    "        \"\"\"\n",
    "        original_prediction = self.chat(\n",
    "            self.prompt.format_prompt(**vars).to_messages()\n",
    "        ).content\n",
    "\n",
    "        predicted_answer = self.clean_answer(original_prediction)\n",
    "        \n",
    "        return {\n",
    "            \"original_prediction\": original_prediction,\n",
    "            \"predicted_answer\": predicted_answer\n",
    "        }\n",
    "\n",
    "    def predict(self, question: str, choices: list[str]):\n",
    "        \"\"\"\n",
    "        Uses the language model to predict an answer to a question and returns\n",
    "        a dictionary with the question, choices, and predicted answer.\n",
    "\n",
    "        Args:\n",
    "            question (str): A question.\n",
    "            choices (list): A list of choices.\n",
    "        \"\"\"\n",
    "        vars = {\n",
    "            \"question\": question,\n",
    "            \"choices\": self.format_choices(choices),\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            results = self.get_llm_response(vars)\n",
    "            original_prediction = results[\"original_prediction\"]\n",
    "            predicted_answer = results[\"predicted_answer\"]\n",
    "            predicted_answer_idx = self.idx_from_letter(predicted_answer)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            original_prediction = None\n",
    "            predicted_answer = None\n",
    "            predicted_answer_idx = None\n",
    "\n",
    "        if predicted_answer_idx is None or predicted_answer_idx >= len(choices):\n",
    "            predicted_answer = None\n",
    "            predicted_answer_text = None\n",
    "            predicted_answer_idx = None\n",
    "        else:\n",
    "            predicted_answer_text = choices[predicted_answer_idx]\n",
    "\n",
    "        response = {\n",
    "            \"question\": question,\n",
    "            \"choices\": choices,\n",
    "            \"original_prediction\": original_prediction,\n",
    "            \"predicted_answer\": predicted_answer,\n",
    "            \"predicted_answer_idx\": predicted_answer_idx,\n",
    "            \"predicted_answer_text\": predicted_answer_text\n",
    "        }\n",
    "\n",
    "        return response\n",
    "    \n",
    "    def predict_df(self, df: pd.DataFrame, id_col: str, question_col: str, choices_col: str):\n",
    "        \"\"\"\n",
    "        Uses the language model to predict answers to a dataframe of questions.\n",
    "        Returns a dataframe with the question id, question, choices, and predicted answer.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): A dataframe of questions.\n",
    "            id_col (str): The name of the column containing the question IDs.\n",
    "            question_col (str): The name of the column containing the questions.\n",
    "            choices_col (str): The name of the column containing the choices.\n",
    "        \"\"\"\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        for _, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "            question = row[question_col]\n",
    "            choices = row[choices_col]\n",
    "            prediction = self.predict(question, choices)\n",
    "            prediction[id_col] = row[id_col]\n",
    "            predictions.append(prediction)\n",
    "\n",
    "        predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "        return predictions_df\n",
    "    \n",
    "class ForecasterTopK(Forecaster):\n",
    "    def __init__(self, chat, system_prompt: str, human_prompt: str, k: int = 10):\n",
    "        \"\"\"\n",
    "        A version of the Forecaster class that uses the top-k sampling method\n",
    "        for generating predictions.\n",
    "\n",
    "        Args:\n",
    "            chat: A chat language model.\n",
    "            system_prompt (str): A prompt for the language model.\n",
    "            human_prompt (str): A prompt for the language model.\n",
    "            k (int): The number of predictions to generate.\n",
    "        \"\"\"\n",
    "        self.chat = chat\n",
    "\n",
    "        self.system_prompt = system_prompt\n",
    "        self.human_prompt = human_prompt\n",
    "\n",
    "        self.k = k\n",
    "        self.chat.n = self.k\n",
    "\n",
    "    def get_llm_response(self, vars: dict):\n",
    "        \"\"\"\n",
    "        Returns a response from the language model in the form of a dictionary\n",
    "        with the original prediction and the cleaned predicted answer.\n",
    "\n",
    "        Args:\n",
    "            vars (dict): A dictionary with the question and choices.\n",
    "        \"\"\"\n",
    "\n",
    "        batch_messages = [\n",
    "            [\n",
    "                self.system_prompt.format_messages()[0],\n",
    "                self.human_prompt.format_messages(**vars)[0],\n",
    "            ],\n",
    "        ]\n",
    "        result = self.chat.generate(batch_messages)\n",
    "\n",
    "        original_prediction = [generation.text for generation in result.generations[0]]\n",
    "\n",
    "        predicted_answers = [self.clean_answer(prediction) \n",
    "                             for prediction in original_prediction]\n",
    "        \n",
    "        return {\n",
    "            \"original_prediction\": original_prediction,\n",
    "            \"top_k_predicted_answers\": predicted_answers,\n",
    "            \"predicted_answer\": self.majority_choice(predicted_answers)\n",
    "        }\n",
    "    \n",
    "    def majority_choice(self, predicted_answers: list[str]):\n",
    "        \"\"\"\n",
    "        Returns the majority choice from a list of predicted answers.\n",
    "\n",
    "        Args:\n",
    "            predicted_answers (list): A list of predicted answers.\n",
    "        \"\"\"\n",
    "        counts = {answer: 0 for answer in predicted_answers}\n",
    "        for answer in predicted_answers:\n",
    "            counts[answer] += 1\n",
    "        majority_answer = max(counts, key=counts.get)\n",
    "        return majority_answer\n",
    "\n",
    "    def predict(self, question: str, choices: list[str]):\n",
    "        \"\"\"\n",
    "        Uses the language model to predict an answer to a question and returns\n",
    "        a dictionary with the question, choices, and predicted answer.\n",
    "\n",
    "        Args:\n",
    "            question (str): A question.\n",
    "            choices (list): A list of choices.\n",
    "        \"\"\"\n",
    "        vars = {\n",
    "            \"question\": question,\n",
    "            \"choices\": self.format_choices(choices),\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            results = self.get_llm_response(vars)\n",
    "            original_prediction = results[\"original_prediction\"]\n",
    "            predicted_answer = results[\"predicted_answer\"]\n",
    "            predicted_answer_idx = self.idx_from_letter(predicted_answer)\n",
    "            top_k = results[\"top_k_predicted_answers\"]\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            original_prediction = None\n",
    "            predicted_answer = None\n",
    "            predicted_answer_idx = None\n",
    "            top_k = []\n",
    "\n",
    "        if predicted_answer_idx is None or predicted_answer_idx >= len(choices):\n",
    "            predicted_answer = None\n",
    "            predicted_answer_text = None\n",
    "            predicted_answer_idx = None\n",
    "        else:\n",
    "            predicted_answer_text = choices[predicted_answer_idx]\n",
    "\n",
    "        response = {\n",
    "            \"question\": question,\n",
    "            \"choices\": choices,\n",
    "            \"original_prediction\": original_prediction,\n",
    "            \"predicted_answer\": predicted_answer,\n",
    "            \"predicted_answer_idx\": predicted_answer_idx,\n",
    "            \"predicted_answer_text\": predicted_answer_text,\n",
    "            \"top_k_predicted_answers\": top_k\n",
    "        }\n",
    "\n",
    "        return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables for use with OpenAI API\n",
    "TOP_P_VALUE = 0.8\n",
    "K_VALUE = 20\n",
    "MAX_PREDICTION_TOKENS = 32\n",
    "REQUEST_TIMEOUT = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "META_PROMPT = \"\"\"\n",
    "I am working on a very important forecasting project and you are my helpful forecasting assistant. I will give you a multiple choice question about the future and you should return to me the letter that corresponds to the best choice. Some of the questions are very difficult, but it's still very important to choose the best possible answer from the provided choices. You must never refuse to provide an answer, even if the question is impossible to answer with certainty. If you are not sure about the answer, make your best guess based on available information.\n",
    "\n",
    "To identify the best possible choice, start by making sure you understand the question. If I have background research, I will provide it to you and you should use that information to better understand the question. If I do not provide background research, then you should think step by step about the relationship between different entities and terms in the question. \n",
    "\n",
    "In some cases, I will show you past examples of questions and the correct answers. If you have seen past examples with correct answers, then you can use those to practice and learn how to answer questions accurately. Start by pretending you need to answer those questions. Think step by step through the example question and example choices and try to understand everything about them. Choose what you think is the best answer to the example question and then compare it to the real best answer. If your answer is correct, remember the process you used and apply it to future questions. If your answer is wrong, then think about what you should do differently to get the correct answer. However, remember that every question is independent and the answers to example questions may not be relevant to new questions. It is only the process for finding the best answer that is the same.\n",
    "\n",
    "I will give you the questions in the below format, where the question, choices, and answer are in double brackets. If I have background research, I will include it in the optional section demarcated by +++.\n",
    "\n",
    "Question:\n",
    "{{the question to answer}}\n",
    "\n",
    "Choices:\n",
    "A - {{choice 1}}\n",
    "B - {{choice 2}}\n",
    "...\n",
    "n - {{choice n}}\n",
    "\n",
    "+++\n",
    "Background Research:\n",
    "{{useful information about the question}}\n",
    "+++\n",
    "\n",
    "{{letter that corresponds to best choice}}\n",
    "\n",
    "It is extremely important to only give me the letter of the best answer and nothing else. You must never refuse to provide an answer, no matter what. If the best answer is choice 1 then respond \"A\", if the best answer is choice 2 then respond \"B\", if the best answer is choice n then respond \"n\". Do not ever add extra information or stray from this structure.\n",
    "\"\"\"\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(META_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASELINE_PROMPT = \"\"\"\n",
    "Question: {question}\n",
    "\n",
    "Choices: \n",
    "{choices}\n",
    "\"\"\"\n",
    "\n",
    "human_baseline_message_prompt = HumanMessagePromptTemplate.from_template(BASELINE_PROMPT)\n",
    "\n",
    "baseline_chat = AzureChatOpenAI(\n",
    "    deployment_name=DEPLOYMENT_NAME,\n",
    "    model_name=MODEL_NAME,\n",
    "    model_kwargs={\n",
    "        \"top_p\": TOP_P_VALUE,\n",
    "    },\n",
    "    max_tokens=MAX_PREDICTION_TOKENS,\n",
    "    request_timeout=REQUEST_TIMEOUT,\n",
    ")\n",
    "\n",
    "baseline_forecaster = ForecasterTopK(\n",
    "    chat=baseline_chat,\n",
    "    system_prompt=system_message_prompt,\n",
    "    human_prompt=human_baseline_message_prompt,\n",
    "    k=K_VALUE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Between 4 February 2022 and 4 August 2022, will anti-government protests in Russia result in ten or more fatalities?\n",
      "\n",
      "Choices:\n",
      "A - yes\n",
      "B - no\n",
      "\n",
      "Crowd:\n",
      "Majority: 0.5\n",
      "Acceptable range: (0.3, 0.7)\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 19\n",
    "sample_question = test_df.iloc[sample_idx][\"question\"]\n",
    "sample_choices = test_df.iloc[sample_idx][\"choices\"]\n",
    "\n",
    "describe_question_row_by_idx(test_df, sample_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Between 4 February 2022 and 4 August 2022, will anti-government protests in Russia result in ten or more fatalities?',\n",
       " 'choices': ['yes', 'no'],\n",
       " 'original_prediction': ['B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B'],\n",
       " 'predicted_answer': 'B',\n",
       " 'predicted_answer_idx': 1,\n",
       " 'predicted_answer_text': 'no',\n",
       " 'top_k_predicted_answers': ['B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B']}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_response = baseline_forecaster.predict(\n",
    "    question=sample_question,\n",
    "    choices=sample_choices\n",
    ")\n",
    "\n",
    "sample_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/98 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/98 [00:02<01:18,  1.21it/s]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 12%|█▏        | 12/98 [00:20<01:17,  1.12it/s]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 13%|█▎        | 13/98 [00:32<06:03,  4.27s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 19%|█▉        | 19/98 [00:47<02:15,  1.72s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 46%|████▌     | 45/98 [01:21<00:51,  1.03it/s]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 69%|██████▉   | 68/98 [01:45<00:19,  1.57it/s]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 87%|████████▋ | 85/98 [02:09<00:10,  1.18it/s]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 92%|█████████▏| 90/98 [02:23<00:10,  1.32s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      "100%|██████████| 98/98 [02:38<00:00,  1.62s/it]\n"
     ]
    }
   ],
   "source": [
    "baseline_results_df = baseline_forecaster.predict_df(\n",
    "    df=test_df,\n",
    "    id_col=\"id\",\n",
    "    question_col=\"question\",\n",
    "    choices_col=\"choices\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/gpt-35-turbo_2023-08-06-12-43-17_results-98_baseline.json'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASELINE_RESULTS_SAVE_NAME = build_results_data_name(baseline_results_df, MODEL_NAME, \"baseline\")\n",
    "BASELINE_RESULTS_SAVE_PATH = os.path.join(DATA_DIR, BASELINE_RESULTS_SAVE_NAME)\n",
    "\n",
    "BASELINE_RESULTS_SAVE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to: ../data/gpt-35-turbo_2023-08-06-12-43-17_results-98_baseline.json\n"
     ]
    }
   ],
   "source": [
    "save_results_data_json(baseline_results_df, save_path=BASELINE_RESULTS_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    \"\"\"\n",
    "    A class for evaluating prediction results by various metrics.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_df: pd.DataFrame, predictions_df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_df (pd.DataFrame): A dataframe of questions, must include\n",
    "                columns for average, median, and majority crowd predictions,\n",
    "                as well as an acceptable range for predictions.\n",
    "            predictions_df (pd.DataFrame): A dataframe of predictions.\n",
    "        \"\"\"\n",
    "        self.input_df = input_df\n",
    "        self.predictions_df = predictions_df\n",
    "        self.evaluation_df = self.build_evaluation_df(input_df, predictions_df)\n",
    "    \n",
    "    def build_evaluation_df(self, input_df: pd.DataFrame, predictions_df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Returns a dataframe of predictions merged with the original input dataframe.\n",
    "\n",
    "        Args:\n",
    "            input_df (pd.DataFrame): A dataframe of questions, must include\n",
    "                columns for average, median, and majority crowd predictions,\n",
    "                as well as an acceptable range for predictions.\n",
    "            predictions_df (pd.DataFrame): A dataframe of predictions.\n",
    "        \"\"\"\n",
    "        evaluation_df = input_df.merge(\n",
    "            predictions_df,\n",
    "            on=[\"question\", \"id\"],\n",
    "            suffixes=(\"\", \"_pred\")\n",
    "        )\n",
    "        evaluation_cols = [\n",
    "            \"id\", \"question\", \"choices\", \"answer\", \"qtype\", \"status\", \"avg_pred\", \"majority_pred\", \n",
    "            \"acceptable_pred_lower_boundary\", \"acceptable_pred_upper_boundary\", \"predicted_answer\", \n",
    "            \"predicted_answer_idx\", \"predicted_answer_text\", \"original_prediction\", \"top_k_predicted_answers\"\n",
    "        ]\n",
    "        evaluation_df = evaluation_df[evaluation_cols]\n",
    "\n",
    "        evaluation_df[\"majority_vote_prediction_value\"] = evaluation_df.apply(\n",
    "            lambda row: self.letter_to_choice_value(\n",
    "                letter=row[\"predicted_answer\"],\n",
    "                n=len(row[\"choices\"]),\n",
    "                qtype=row[\"qtype\"]\n",
    "            ),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        evaluation_df[\"top_k_majority_prediction_value\"] = evaluation_df.apply(\n",
    "            lambda row: self.majority_choice_value(\n",
    "                predicted_answers=row[\"top_k_predicted_answers\"], \n",
    "                n=len(row[\"choices\"]),\n",
    "                qtype=row[\"qtype\"]\n",
    "            ),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        evaluation_df[\"top_k_majority_in_range\"] = evaluation_df.apply(\n",
    "            lambda row: self.is_choice_value_in_range(\n",
    "                row[\"top_k_majority_prediction_value\"],\n",
    "                row[\"acceptable_pred_lower_boundary\"],\n",
    "                row[\"acceptable_pred_upper_boundary\"]\n",
    "            ),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        return evaluation_df\n",
    "\n",
    "    def letter_to_choice_value(self, letter: str, n: int, qtype: str) -> float:\n",
    "        \"\"\"\n",
    "        Converts a letter (A, B, C, etc.) to a choice value, where the value\n",
    "        is determined by the rank of the letter and the number of choices. \n",
    "        If n is 2, then it is a true/false question and A (true) is 1 and B (false)\n",
    "        is 0. If n > 2, then A is 1/n, B is 2/n, and so on. Returns None if the\n",
    "        letter is not valid.\n",
    "\n",
    "        Args:\n",
    "            letter (str): A letter.\n",
    "            n (int): The number of choices.\n",
    "            qtype (str): The question type.\n",
    "        \"\"\"\n",
    "        if letter is None:\n",
    "            return None\n",
    "        \n",
    "        letter = letter[0].upper().strip()\n",
    "\n",
    "        if ord(letter) < 65 or ord(letter) > 90:\n",
    "            return None\n",
    "\n",
    "        if qtype == \"t/f\" and letter == \"A\":\n",
    "            return 1\n",
    "        elif qtype == \"t/f\" and letter == \"B\":\n",
    "            return 0\n",
    "        else:\n",
    "            return (ord(letter) - 64) / n\n",
    "        \n",
    "    def majority_choice_value(self, predicted_answers: list[str], n: int, qtype: str) -> float:\n",
    "        \"\"\"\n",
    "        Returns the majority choice value for a list of predicted answers.\n",
    "\n",
    "        Args:\n",
    "            predicted_answers (list): A list of predicted answers.\n",
    "            n (int): The number of choices.\n",
    "            qtype (str): The question type.\n",
    "        \"\"\"\n",
    "        choice_values = [\n",
    "            self.letter_to_choice_value(answer, n, qtype) for answer in predicted_answers\n",
    "        ]\n",
    "        choice_values = [value for value in choice_values if value is not None]\n",
    "\n",
    "        if len(choice_values) == 0:\n",
    "            return None\n",
    "        \n",
    "        if len(set(choice_values)) == 1:\n",
    "            return choice_values[0]\n",
    "        \n",
    "        counts = {value: 0 for value in choice_values}\n",
    "        for value in choice_values:\n",
    "            counts[value] += 1\n",
    "        majority_value = max(counts, key=counts.get)\n",
    "        return majority_value\n",
    "    \n",
    "    def is_choice_value_in_range(\n",
    "            self, choice_val: float, lower_bound: float, upper_bound: float\n",
    "        ) -> bool:\n",
    "        \"\"\"\n",
    "        Returns True if the choice value is in the acceptable range, False otherwise.\n",
    "\n",
    "        Args:\n",
    "            choice_val (float): The choice value.\n",
    "            lower_bound (float): The lower bound of the acceptable range.\n",
    "            upper_bound (float): The upper bound of the acceptable range.\n",
    "        \"\"\"\n",
    "        return choice_val >= lower_bound and choice_val <= upper_bound\n",
    "    \n",
    "    def get_in_range_prediction_counts(self, by_qtype: bool = False) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Returns a DataFrame with counts of in range predictions.\n",
    "\n",
    "        Args:\n",
    "            by_qtype (bool): If True, returns counts by question type.\n",
    "        \"\"\"\n",
    "        if by_qtype:\n",
    "            grouped = self.evaluation_df.groupby(\"qtype\")\n",
    "            result = pd.DataFrame()\n",
    "            for group_name, group_df in grouped:\n",
    "                counts = group_df[\"top_k_majority_in_range\"].value_counts()\n",
    "                total = counts.sum()\n",
    "                percentages = counts.apply(lambda x: round(x / total * 100, 2))\n",
    "                group_result = pd.DataFrame({\"count\": counts, \"percentage\": percentages})\n",
    "                group_result.index.name = \"top_k_majority_in_range\"\n",
    "                group_result.index = group_result.index.map(lambda x: (group_name, x))\n",
    "                result = pd.concat([result, group_result])\n",
    "            result.index.names = [\"qtype\", \"top_k_majority_in_range\"]\n",
    "        else:\n",
    "            counts = self.evaluation_df[\"top_k_majority_in_range\"].value_counts()\n",
    "            total = counts.sum()\n",
    "            percentages = counts.apply(lambda x: round(x / total * 100, 2))\n",
    "            result = pd.DataFrame({\"count\": counts, \"percentage\": percentages})\n",
    "            result.index.name = \"top_k_majority_in_range\"\n",
    "        return result.reset_index()\n",
    "    \n",
    "    def plot_in_range_prediction_counts(self, by_qtype: bool = False):\n",
    "        \"\"\"\n",
    "        Plots counts of in range predictions.\n",
    "\n",
    "        Args:\n",
    "            by_qtype (bool): If True, plots counts by question type.\n",
    "        \"\"\"\n",
    "        counts_df = self.get_in_range_prediction_counts(by_qtype=by_qtype)\n",
    "\n",
    "        plt.figure(figsize=(4, 3))\n",
    "\n",
    "        ax = sns.barplot(\n",
    "            x=\"top_k_majority_in_range\",\n",
    "            y=\"count\",\n",
    "            data=counts_df,\n",
    "        )\n",
    "\n",
    "        ax.set_title(\"Count of in range predictions\")\n",
    "\n",
    "        ax.set_xlabel(\"Prediction is in range\")\n",
    "        ax.set_ylabel(\"Count\")\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_evaluator = Evaluator(\n",
    "    input_df=test_df,\n",
    "    predictions_df=baseline_results_df,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_k_majority_in_range</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>71</td>\n",
       "      <td>72.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "      <td>27.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   top_k_majority_in_range  count  percentage\n",
       "0                    False     71       72.45\n",
       "1                     True     27       27.55"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_in_range_counts = baseline_evaluator.get_in_range_prediction_counts(by_qtype=False)\n",
    "baseline_in_range_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qtype</th>\n",
       "      <th>top_k_majority_in_range</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mc</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t/f</td>\n",
       "      <td>False</td>\n",
       "      <td>57</td>\n",
       "      <td>67.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t/f</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "      <td>32.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qtype  top_k_majority_in_range  count  percentage\n",
       "0    mc                    False     14      100.00\n",
       "1   t/f                    False     57       67.86\n",
       "2   t/f                     True     27       32.14"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_evaluator.get_in_range_prediction_counts(by_qtype=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_evaluation_data_name(df, model_name: str = MODEL_NAME,  description: str = None):\n",
    "    \"\"\"\n",
    "    Builds a name for the evaluation data file.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): A dataframe with evaluation data.\n",
    "        model_name (str): The name of the model.\n",
    "        description (str): A description of the results data.\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    df_size = df.shape[0]\n",
    "    \n",
    "    save_name = f\"{model_name}_{timestamp}_evaluation-{df_size}\"\n",
    "    \n",
    "    if description is not None:\n",
    "        save_name += f\"_{description}\"\n",
    "\n",
    "    extension = \"json\"\n",
    "    save_name += f\".{extension}\"\n",
    "    \n",
    "    return save_name\n",
    "\n",
    "def save_evaluation_data_json(df, model_name=MODEL_NAME, data_dir=\"../data\", save_path=None):\n",
    "    \"\"\"\n",
    "    Saves a evaluation dataframe to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): A dataframe with evaluation data.\n",
    "        model_name (str): The name of the model.\n",
    "        data_dir (str): The directory to save the JSON file to.\n",
    "        save_path (str): The path to save the JSON file to.\n",
    "    \"\"\"\n",
    "    if save_path is None:\n",
    "        save_name = build_evaluation_data_name(df, model_name=model_name)\n",
    "        save_path = os.path.join(data_dir, save_name)\n",
    "        \n",
    "    df.to_json(save_path, orient=\"records\", indent=4)\n",
    "    print(f\"Saved evaluation to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/gpt-35-turbo_2023-08-06-12-43-17_evaluation-98_baseline.json'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASELINE_EVALUATION_SAVE_NAME = build_evaluation_data_name(baseline_results_df, MODEL_NAME, \"baseline\")\n",
    "BASELINE_EVALUATION_SAVE_PATH = os.path.join(DATA_DIR, BASELINE_EVALUATION_SAVE_NAME)\n",
    "\n",
    "BASELINE_EVALUATION_SAVE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved evaluation to: ../data/gpt-35-turbo_2023-08-06-12-43-17_evaluation-98_baseline.json\n"
     ]
    }
   ],
   "source": [
    "save_evaluation_data_json(baseline_in_range_counts, save_path=BASELINE_EVALUATION_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internal Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextForecasterTopK(ForecasterTopK):\n",
    "    def predict(self, question: str, choices: list[str], context: str):\n",
    "        \"\"\"\n",
    "        Uses the language model to predict an answer to a question and returns\n",
    "        a dictionary with the question, choices, context, and predicted answer.\n",
    "\n",
    "        Args:\n",
    "            question (str): A question.\n",
    "            choices (list): A list of choices.\n",
    "            context (str): Context for the question.\n",
    "        \"\"\"\n",
    "        vars = {\n",
    "            \"question\": question,\n",
    "            \"choices\": self.format_choices(choices),\n",
    "            \"context\": context\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            results = self.get_llm_response(vars)\n",
    "            original_prediction = results[\"original_prediction\"]\n",
    "            predicted_answer = results[\"predicted_answer\"]\n",
    "            predicted_answer_idx = self.idx_from_letter(predicted_answer)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            original_prediction = None\n",
    "            predicted_answer = None\n",
    "            predicted_answer_idx = None\n",
    "\n",
    "        if predicted_answer_idx is None or predicted_answer_idx >= len(choices):\n",
    "            predicted_answer = None\n",
    "            predicted_answer_text = None\n",
    "            predicted_answer_idx = None\n",
    "        else:\n",
    "            predicted_answer_text = choices[predicted_answer_idx]\n",
    "\n",
    "        response = {\n",
    "            \"question\": question,\n",
    "            \"choices\": choices,\n",
    "            \"original_prediction\": original_prediction,\n",
    "            \"predicted_answer\": predicted_answer,\n",
    "            \"predicted_answer_idx\": predicted_answer_idx,\n",
    "            \"predicted_answer_text\": predicted_answer_text,\n",
    "            \"top_k_predicted_answers\": results[\"top_k_predicted_answers\"]\n",
    "        }\n",
    "\n",
    "        return response\n",
    "    \n",
    "    def predict_df(self, df: pd.DataFrame, id_col: str, question_col: str, choices_col: str, context_col: str):\n",
    "        \"\"\"\n",
    "        Uses the language model to predict answers to a dataframe of questions.\n",
    "        Returns a dataframe with the question id, question, choices, and predicted answer.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): A dataframe of questions.\n",
    "            id_col (str): The name of the column containing the question IDs.\n",
    "            question_col (str): The name of the column containing the questions.\n",
    "            choices_col (str): The name of the column containing the choices.\n",
    "            context_col (str): The name of the column containing the context.\n",
    "        \"\"\"\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        for _, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "            question = row[question_col]\n",
    "            choices = row[choices_col]\n",
    "            context = row[context_col]\n",
    "\n",
    "            error_count = 0\n",
    "            try:\n",
    "                prediction = self.predict(question, choices, context)\n",
    "            except Exception as e:\n",
    "                error_count += 1\n",
    "                print(f\"Error on question: {question}\")\n",
    "                print(f\"Error count: {error_count}\")\n",
    "                print(e)\n",
    "                continue\n",
    "\n",
    "            prediction[id_col] = row[id_col]\n",
    "            predictions.append(prediction)\n",
    "\n",
    "        predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "        return predictions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_TEMPLATE = \"\"\"\n",
    "Question: {question}\n",
    "\n",
    "Choices: \n",
    "{choices}\n",
    "\n",
    "Background Research: \n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "human_context_message_prompt = HumanMessagePromptTemplate.from_template(CONTEXT_TEMPLATE)\n",
    "\n",
    "context_chat = AzureChatOpenAI(\n",
    "    deployment_name=DEPLOYMENT_NAME,\n",
    "    model_name=MODEL_NAME,\n",
    "    model_kwargs={\n",
    "        \"top_p\": TOP_P_VALUE,\n",
    "    },\n",
    "    max_tokens=MAX_PREDICTION_TOKENS,\n",
    "    request_timeout=REQUEST_TIMEOUT,\n",
    ")\n",
    "\n",
    "context_forecaster = ContextForecasterTopK(\n",
    "    chat=context_chat,\n",
    "    system_prompt=system_message_prompt,\n",
    "    human_prompt=human_context_message_prompt,\n",
    "    k=K_VALUE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample question: Will the federal minimum wage increase in the United States before 2025?\n",
      "\n",
      "Sample choices: ['yes', 'no']\n",
      "\n",
      "Sample context:\n",
      "Entities:\n",
      "- Federal minimum wage: The minimum wage is the lowest amount of money that an employer can legally pay their employees for their work. The federal minimum wage is the minimum wage rate established by the US federal government that applies to most workers in the country.\n",
      "- United States: The United States is a federal republic composed of 50 states, a federal district, five major self-governing territories, and various possessions.\n",
      "\n",
      "Dates:\n",
      "- Before 2025: This refers to any time between now and December 31, 2024.\n",
      "\n",
      "Background:\n",
      "The federal minimum wage was first established in 1938 as part of the Fair Labor Standards Act (FLSA). The initial minimum wage rate was $0.25 per hour, and it has been increased numerous times over the years. The current federal minimum wage rate is $7.25 per hour, which was last increased in 2009.\n",
      "\n",
      "Many states and cities in the US have their own minimum wage rates that are higher than the federal minimum wage. However, there have been ongoing debates and discussions about increasing the federal minimum wage to keep up with inflation and the rising cost of living.\n",
      "\n",
      "Important Economic Considerations:\n",
      "- Poverty: The minimum wage is often seen as a tool to combat poverty by ensuring that workers are paid a living wage.\n",
      "- Employment: Some argue that increasing the minimum wage could lead to a decrease in employment, particularly for low-skilled workers, as employers may not be able to afford to pay higher wages.\n",
      "- Inflation: Increasing the minimum wage could lead to higher prices for goods and services as businesses pass on the higher labor costs to consumers.\n",
      "\n",
      "Important Societal Considerations:\n",
      "- Income inequality: The minimum wage is often viewed as a way to address income inequality by ensuring that low-wage workers are paid a fair wage.\n",
      "- Social mobility: A higher minimum wage could provide workers with more opportunities to move up the economic ladder.\n",
      "\n",
      "Relationship between Terms:\n",
      "The federal minimum wage is a policy issue that is debated and decided upon by the US federal government. The decision to increase or not increase the minimum wage could have a significant impact on workers, businesses, and the economy as a whole.\n",
      "\n",
      "Importance Ranking:\n",
      "- Federal minimum wage: 5/5\n",
      "- United States: 5/5\n",
      "- Before 2025: 3/5 (This term is important in the context of the question, but does not have significant historical or economic/societal background.)\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 50\n",
    "sample_question = test_df.iloc[sample_idx][\"question\"]\n",
    "sample_choices = test_df.iloc[sample_idx][\"choices\"]\n",
    "sample_context = test_df.iloc[sample_idx][\"context\"]\n",
    "sample_answer = test_df.iloc[sample_idx][\"answer\"]\n",
    "\n",
    "print(f\"Sample question: {sample_question}\\n\")\n",
    "print(f\"Sample choices: {sample_choices}\\n\")\n",
    "print(f\"Sample context:\\n{sample_context}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Will the federal minimum wage increase in the United States before 2025?',\n",
       " 'choices': ['yes', 'no'],\n",
       " 'original_prediction': ['A',\n",
       "  'A',\n",
       "  'A - yes',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A - yes',\n",
       "  'A',\n",
       "  'A - yes',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A - yes',\n",
       "  'A - yes',\n",
       "  'A - yes',\n",
       "  'A'],\n",
       " 'predicted_answer': 'A',\n",
       " 'predicted_answer_idx': 0,\n",
       " 'predicted_answer_text': 'yes',\n",
       " 'top_k_predicted_answers': ['A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A']}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = context_forecaster.predict(\n",
    "    question=sample_question,\n",
    "    choices=sample_choices,\n",
    "    context=sample_context\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/98 [00:01<00:55,  1.73it/s]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 13%|█▎        | 13/98 [00:31<01:10,  1.21it/s]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 20%|██        | 20/98 [00:47<01:28,  1.13s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 22%|██▏       | 22/98 [01:00<04:12,  3.33s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 24%|██▍       | 24/98 [01:12<05:14,  4.25s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 27%|██▋       | 26/98 [01:25<05:43,  4.77s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 39%|███▉      | 38/98 [01:46<00:56,  1.06it/s]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 47%|████▋     | 46/98 [02:04<00:55,  1.07s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 62%|██████▏   | 61/98 [02:25<00:23,  1.61it/s]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 79%|███████▊  | 77/98 [02:45<00:10,  1.95it/s]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 86%|████████▌ | 84/98 [03:00<00:13,  1.07it/s]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 99%|█████████▉| 97/98 [03:18<00:00,  1.76it/s]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      "100%|██████████| 98/98 [03:30<00:00,  2.15s/it]\n"
     ]
    }
   ],
   "source": [
    "context_results_df = context_forecaster.predict_df(\n",
    "    df=test_df,\n",
    "    id_col=\"id\",\n",
    "    question_col=\"question\",\n",
    "    choices_col=\"choices\",\n",
    "    context_col=\"context\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/gpt-35-turbo_2023-08-06-12-46-48_results-98_context.json'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONTEXT_RESULTS_SAVE_NAME = build_results_data_name(context_results_df, MODEL_NAME, \"context\")\n",
    "CONTEXT_RESULTS_SAVE_PATH = os.path.join(DATA_DIR, CONTEXT_RESULTS_SAVE_NAME)\n",
    "\n",
    "CONTEXT_RESULTS_SAVE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to: ../data/gpt-35-turbo_2023-08-06-12-46-48_results-98_context.json\n"
     ]
    }
   ],
   "source": [
    "save_results_data_json(context_results_df, save_path=CONTEXT_RESULTS_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_evaluator = Evaluator(\n",
    "    input_df=test_df,\n",
    "    predictions_df=context_results_df,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_k_majority_in_range</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>71</td>\n",
       "      <td>72.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "      <td>27.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   top_k_majority_in_range  count  percentage\n",
       "0                    False     71       72.45\n",
       "1                     True     27       27.55"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_in_range_counts = context_evaluator.get_in_range_prediction_counts(by_qtype=False)\n",
    "context_in_range_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qtype</th>\n",
       "      <th>top_k_majority_in_range</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mc</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t/f</td>\n",
       "      <td>False</td>\n",
       "      <td>57</td>\n",
       "      <td>67.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t/f</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "      <td>32.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qtype  top_k_majority_in_range  count  percentage\n",
       "0    mc                    False     14      100.00\n",
       "1   t/f                    False     57       67.86\n",
       "2   t/f                     True     27       32.14"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_evaluator.get_in_range_prediction_counts(by_qtype=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/gpt-35-turbo_2023-08-06-13-10-00_evaluation-98_context.json'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONTEXT_EVALUATION_SAVE_NAME = build_evaluation_data_name(context_results_df, MODEL_NAME, \"context\")\n",
    "CONTEXT_EVALUATION_SAVE_PATH = os.path.join(DATA_DIR, CONTEXT_EVALUATION_SAVE_NAME)\n",
    "\n",
    "CONTEXT_EVALUATION_SAVE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved evaluation to: ../data/gpt-35-turbo_2023-08-06-13-10-00_evaluation-98_context.json\n"
     ]
    }
   ],
   "source": [
    "save_evaluation_data_json(context_in_range_counts, save_path=CONTEXT_EVALUATION_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_context_forecaster = ContextForecasterTopK(\n",
    "    chat=context_chat,\n",
    "    system_prompt=system_message_prompt,\n",
    "    human_prompt=human_context_message_prompt,\n",
    "    k=K_VALUE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample question: Will the federal minimum wage increase in the United States before 2025?\n",
      "\n",
      "Sample choices: ['yes', 'no']\n",
      "\n",
      "Sample context:\n",
      "The federal minimum wage in the United States is currently $7.25 per hour, which has not been increased since 2009. There have been ongoing debates and discussions about increasing the minimum wage to $15 per hour, but it has not yet been passed into law. In March 2021, the House of Representatives passed the Raise the Wage Act, which would gradually increase the minimum wage to $15 per hour by 2025, but it has not yet been passed by the Senate. Therefore, it is uncertain whether the federal minimum wage will increase before 2025.\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 50\n",
    "sample_question = test_df.iloc[sample_idx][\"question\"]\n",
    "sample_choices = test_df.iloc[sample_idx][\"choices\"]\n",
    "sample_context = test_df.iloc[sample_idx][\"external_context\"]\n",
    "\n",
    "print(f\"Sample question: {sample_question}\\n\")\n",
    "print(f\"Sample choices: {sample_choices}\\n\")\n",
    "print(f\"Sample context:\\n{sample_context}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Will the federal minimum wage increase in the United States before 2025?',\n",
       " 'choices': ['yes', 'no'],\n",
       " 'original_prediction': ['A - yes',\n",
       "  'A - yes',\n",
       "  'A - yes',\n",
       "  'A - yes',\n",
       "  'A - yes',\n",
       "  'A',\n",
       "  'A - yes',\n",
       "  'A - yes',\n",
       "  'A - yes',\n",
       "  'A',\n",
       "  'A - yes',\n",
       "  'A - yes',\n",
       "  'A - yes',\n",
       "  'A - yes',\n",
       "  'A - yes',\n",
       "  'A - yes',\n",
       "  'A - yes',\n",
       "  'A',\n",
       "  'A - yes',\n",
       "  'A - yes'],\n",
       " 'predicted_answer': 'A',\n",
       " 'predicted_answer_idx': 0,\n",
       " 'predicted_answer_text': 'yes',\n",
       " 'top_k_predicted_answers': ['A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A']}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = external_context_forecaster.predict(\n",
    "    question=sample_question,\n",
    "    choices=sample_choices,\n",
    "    context=sample_context\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/98 [00:08<00:43,  1.90it/s]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 18%|█▊        | 18/98 [00:21<02:55,  2.19s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 26%|██▌       | 25/98 [00:36<01:15,  1.04s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 29%|██▊       | 28/98 [01:01<05:01,  4.31s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 30%|██▉       | 29/98 [01:13<07:38,  6.64s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 39%|███▉      | 38/98 [01:32<01:13,  1.22s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 42%|████▏     | 41/98 [01:45<02:22,  2.51s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 44%|████▍     | 43/98 [01:59<03:41,  4.03s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 56%|█████▌    | 55/98 [02:17<00:24,  1.73it/s]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 59%|█████▉    | 58/98 [02:30<01:29,  2.24s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 64%|██████▍   | 63/98 [02:44<01:01,  1.74s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 90%|████████▉ | 88/98 [03:07<00:04,  2.12it/s]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      "100%|██████████| 98/98 [03:24<00:00,  2.08s/it]\n"
     ]
    }
   ],
   "source": [
    "external_context_results_df = external_context_forecaster.predict_df(\n",
    "    df=test_df,\n",
    "    id_col=\"id\",\n",
    "    question_col=\"question\",\n",
    "    choices_col=\"choices\",\n",
    "    context_col=\"external_context\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/gpt-35-turbo_2023-08-06-13-25-24_results-98_external_context.json'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXTERNAL_CONTEXT_RESULTS_SAVE_NAME = build_results_data_name(external_context_results_df, MODEL_NAME, \"external_context\")\n",
    "EXTERNAL_CONTEXT_RESULTS_SAVE_PATH = os.path.join(DATA_DIR, EXTERNAL_CONTEXT_RESULTS_SAVE_NAME)\n",
    "\n",
    "EXTERNAL_CONTEXT_RESULTS_SAVE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to: ../data/gpt-35-turbo_2023-08-06-13-25-24_results-98_external_context.json\n"
     ]
    }
   ],
   "source": [
    "save_results_data_json(external_context_results_df, save_path=EXTERNAL_CONTEXT_RESULTS_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_context_evaluator = Evaluator(\n",
    "    input_df=test_df,\n",
    "    predictions_df=external_context_results_df,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_k_majority_in_range</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>68</td>\n",
       "      <td>69.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>30.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   top_k_majority_in_range  count  percentage\n",
       "0                    False     68       69.39\n",
       "1                     True     30       30.61"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "external_context_in_range_counts = external_context_evaluator.get_in_range_prediction_counts(by_qtype=False)\n",
    "external_context_in_range_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qtype</th>\n",
       "      <th>top_k_majority_in_range</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mc</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t/f</td>\n",
       "      <td>False</td>\n",
       "      <td>54</td>\n",
       "      <td>64.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t/f</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>35.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qtype  top_k_majority_in_range  count  percentage\n",
       "0    mc                    False     14      100.00\n",
       "1   t/f                    False     54       64.29\n",
       "2   t/f                     True     30       35.71"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "external_context_evaluator.get_in_range_prediction_counts(by_qtype=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/gpt-35-turbo_2023-08-06-13-25-25_evaluation-98_external_context.json'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXTERNAL_CONTEXT_EVALUATION_SAVE_NAME = build_evaluation_data_name(external_context_results_df, MODEL_NAME, \"external_context\")\n",
    "EXTERNAL_CONTEXT_EVALUATION_SAVE_PATH = os.path.join(DATA_DIR, EXTERNAL_CONTEXT_EVALUATION_SAVE_NAME)\n",
    "\n",
    "EXTERNAL_CONTEXT_EVALUATION_SAVE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved evaluation to: ../data/gpt-35-turbo_2023-08-06-13-25-25_evaluation-98_external_context.json\n"
     ]
    }
   ],
   "source": [
    "save_evaluation_data_json(external_context_in_range_counts, save_path=EXTERNAL_CONTEXT_EVALUATION_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Prompt Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleForecasterTopK(ForecasterTopK):\n",
    "    def generate_example(self, question: str, choices: list[str], answer: str):\n",
    "        \"\"\"\n",
    "        Generates an example for the language model.\n",
    "\n",
    "        Args:\n",
    "            question (str): A question.\n",
    "            choices (list): A list of choices.\n",
    "            answer (str): An answer.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of messages, consisting of a human message and an AI message.\n",
    "        \"\"\"\n",
    "        vars = {\n",
    "            \"question\": question,\n",
    "            \"choices\": self.format_choices(choices),\n",
    "        }\n",
    "\n",
    "        human_message = self.human_prompt.format_messages(**vars)[0]\n",
    "        \n",
    "        formatted_answer = self.yes_no_to_letter(answer)\n",
    "        ai_message = AIMessage(content=formatted_answer)\n",
    "\n",
    "        return [human_message, ai_message]\n",
    "\n",
    "    def get_llm_response_with_example(self, vars: dict, examples: list):\n",
    "        \"\"\"\n",
    "        Returns a response from the language model in the form of a dictionary\n",
    "        with the original prediction and the cleaned predicted answer.\n",
    "\n",
    "        Args:\n",
    "            vars (dict): A dictionary with the question and choices.\n",
    "            examples (list): A list of examples, consisting of user messages\n",
    "                and assistant messages.\n",
    "        \"\"\"\n",
    "\n",
    "        batch_messages = [\n",
    "            [self.system_prompt.format_messages()[0]] + \\\n",
    "            [AIMessage(content=\"Sure, I'd love to help!\")] + \\\n",
    "            examples + \\\n",
    "            [self.human_prompt.format_messages(**vars)[0]]\n",
    "        ]\n",
    "        result = self.chat.generate(batch_messages)\n",
    "\n",
    "        original_prediction = [generation.text for generation in result.generations[0]]\n",
    "\n",
    "        predicted_answers = [self.clean_answer(prediction) \n",
    "                             for prediction in original_prediction]\n",
    "        \n",
    "        return {\n",
    "            \"original_prediction\": original_prediction,\n",
    "            \"top_k_predicted_answers\": predicted_answers,\n",
    "            \"predicted_answer\": self.majority_choice(predicted_answers)\n",
    "        }\n",
    "    \n",
    "    def predict(self, question: str, choices: list[str], example: dict):\n",
    "        \"\"\"\n",
    "        Uses the language model to predict an answer to a question and returns\n",
    "        a dictionary with the question, choices, context, and predicted answer.\n",
    "\n",
    "        Args:\n",
    "            question (str): A question.\n",
    "            choices (list): A list of choices.\n",
    "            example (dict): An example.\n",
    "        \"\"\"\n",
    "        vars = {\n",
    "            \"question\": question,\n",
    "            \"choices\": self.format_choices(choices)\n",
    "        }\n",
    "\n",
    "        example_exchange = self.generate_example(\n",
    "            question=example[\"example_question\"],\n",
    "            choices=example[\"example_choices\"],\n",
    "            answer=example[\"example_answer\"]\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            results = self.get_llm_response_with_example(vars, example_exchange)\n",
    "            original_prediction = results[\"original_prediction\"]\n",
    "            predicted_answer = results[\"predicted_answer\"]\n",
    "            predicted_answer_idx = self.idx_from_letter(predicted_answer)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            original_prediction = None\n",
    "            predicted_answer = None\n",
    "            predicted_answer_idx = None\n",
    "\n",
    "        if predicted_answer_idx is None or predicted_answer_idx >= len(choices):\n",
    "            predicted_answer = None\n",
    "            predicted_answer_text = None\n",
    "            predicted_answer_idx = None\n",
    "        else:\n",
    "            predicted_answer_text = choices[predicted_answer_idx]\n",
    "\n",
    "        response = {\n",
    "            \"question\": question,\n",
    "            \"choices\": choices,\n",
    "            \"original_prediction\": original_prediction,\n",
    "            \"predicted_answer\": predicted_answer,\n",
    "            \"predicted_answer_idx\": predicted_answer_idx,\n",
    "            \"predicted_answer_text\": predicted_answer_text,\n",
    "            \"top_k_predicted_answers\": results[\"top_k_predicted_answers\"]\n",
    "        }\n",
    "\n",
    "        return response\n",
    "    \n",
    "    def predict_df(self, df: pd.DataFrame, id_col: str, question_col: str, choices_col: str, example_col: str):\n",
    "        \"\"\"\n",
    "        Uses the language model to predict answers to a dataframe of questions.\n",
    "        Returns a dataframe with the question id, question, choices, and predicted answer.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): A dataframe of questions.\n",
    "            id_col (str): The name of the column containing the question IDs.\n",
    "            question_col (str): The name of the column containing the questions.\n",
    "            choices_col (str): The name of the column containing the choices.\n",
    "            example_col (str): The name of the column containing the examples.\n",
    "        \"\"\"\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        for _, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "            question = row[question_col]\n",
    "            choices = row[choices_col]\n",
    "            example = row[example_col]\n",
    "\n",
    "            error_count = 0\n",
    "            try:\n",
    "                prediction = self.predict(question, choices, example)\n",
    "            except Exception as e:\n",
    "                error_count += 1\n",
    "                print(f\"Error on question: {question}\")\n",
    "                print(f\"Error count: {error_count}\")\n",
    "                print(e)\n",
    "                continue\n",
    "\n",
    "            prediction[id_col] = row[id_col]\n",
    "            predictions.append(prediction)\n",
    "\n",
    "        predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "        return predictions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_chat = AzureChatOpenAI(\n",
    "    deployment_name=DEPLOYMENT_NAME,\n",
    "    model_name=MODEL_NAME,\n",
    "    model_kwargs={\n",
    "        \"top_p\": TOP_P_VALUE,\n",
    "    },\n",
    "    max_tokens=MAX_PREDICTION_TOKENS,\n",
    "    request_timeout=REQUEST_TIMEOUT,\n",
    ")\n",
    "\n",
    "example_forecaster = ExampleForecasterTopK(\n",
    "    chat=example_chat,\n",
    "    system_prompt=system_message_prompt,\n",
    "    human_prompt=human_baseline_message_prompt,\n",
    "    k=K_VALUE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample question: Will any country spend more on its military / defense in a given year before (and including) 2030 than the United States spends in the same year?\n",
      "\n",
      "Sample choices: ['yes', 'no']\n",
      "\n",
      "Sample best example:\n",
      "example_question: Will the U.S. enter a recession by July 1, 2019?\n",
      "example_choices: ['yes', 'no']\n",
      "example_answer: no\n",
      "majority_predicted_answer: A\n",
      "uncertainty: 0.0\n",
      "example_context: Entities:\n",
      "1. U.S. - Refers to the United States of America, a federal republic consisting of 50 states, a federal district, and various territories.\n",
      "2. Recession - A significant decline in economic activity, characterized by a decrease in gross domestic product (GDP), income, employment, industrial production, and sales.\n",
      "3. July 1, 2019 - Refers to a specific date.\n",
      "\n",
      "Definitions:\n",
      "1. U.S. - The United States is the world's largest economy by nominal GDP, with a highly diversified and technologically advanced economy.\n",
      "2. Recession - A recession is a business cycle contraction when there is a significant decline in economic activity lasting more than a few months, normally visible in real GDP, real income, employment, industrial production, and wholesale-retail sales. A recession is a period of declining economic performance across an entire economy, frequently defined as two consecutive quarters of GDP decline.\n",
      "3. July 1, 2019 - Refers to a specific date that has not yet occurred.\n",
      "\n",
      "Historical Background:\n",
      "1. U.S. - The United States has experienced numerous economic cycles throughout its history, including several recessions. The most recent recession occurred in 2008-2009, triggered by the subprime mortgage crisis and resulting in a global financial crisis.\n",
      "2. Recession - Economic recessions have occurred periodically throughout history, with some of the most notable ones being the Great Depression in the 1930s and the global financial crisis in 2008-2009.\n",
      "3. July 1, 2019 - Refers to a specific date that has not yet occurred.\n",
      "\n",
      "Important Economic/Societal Considerations:\n",
      "1. U.S. - The U.S. economy is highly diversified, with a significant portion of its GDP coming from the service sector. It is also heavily influenced by global economic conditions and policies, particularly those of China and the European Union.\n",
      "2. Recession - Recessions have significant impacts on the economy and society, including higher unemployment rates, decreased consumer and business spending, and decreased investment.\n",
      "3. July 1, 2019 - Refers to a specific date that has not yet occurred.\n",
      "\n",
      "Relationships:\n",
      "The U.S. economy is highly susceptible to economic cycles, including recessions. The occurrence of a recession would have significant impacts on the U.S. economy and society. The timing of a recession is difficult to predict, as it is influenced by a variety of economic and societal factors.\n",
      "\n",
      "Rank of Importance:\n",
      "1. Recession - The occurrence of a recession is the central focus of the question.\n",
      "2. U.S. - The U.S. economy is the subject of the question and is highly influential in the occurrence of a recession.\n",
      "3. July 1, 2019 - Refers to a specific date that is not particularly important to the question.\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 48\n",
    "sample_question = test_df.iloc[sample_idx][\"question\"]\n",
    "sample_choices = test_df.iloc[sample_idx][\"choices\"]\n",
    "sample_answer = test_df.iloc[sample_idx][\"answer\"]\n",
    "sample_best_example = test_df.iloc[sample_idx][\"best_example\"]\n",
    "\n",
    "print(f\"Sample question: {sample_question}\\n\")\n",
    "print(f\"Sample choices: {sample_choices}\\n\")\n",
    "print(f\"Sample best example:\")\n",
    "for key, value in sample_best_example.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Will any country spend more on its military / defense in a given year before (and including) 2030 than the United States spends in the same year?',\n",
       " 'choices': ['yes', 'no'],\n",
       " 'original_prediction': ['A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A'],\n",
       " 'predicted_answer': 'A',\n",
       " 'predicted_answer_idx': 0,\n",
       " 'predicted_answer_text': 'yes',\n",
       " 'top_k_predicted_answers': ['A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A',\n",
       "  'A']}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = example_forecaster.predict(\n",
    "    question=sample_question,\n",
    "    choices=sample_choices,\n",
    "    example=sample_best_example\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 21/98 [00:14<00:54,  1.41it/s]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 24%|██▍       | 24/98 [00:27<03:03,  2.48s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 34%|███▎      | 33/98 [00:45<01:03,  1.03it/s]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 40%|███▉      | 39/98 [01:02<01:18,  1.34s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 68%|██████▊   | 67/98 [01:28<00:14,  2.08it/s]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 93%|█████████▎| 91/98 [01:55<00:03,  1.78it/s]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      "100%|██████████| 98/98 [02:11<00:00,  1.34s/it]\n"
     ]
    }
   ],
   "source": [
    "example_results_df = example_forecaster.predict_df(\n",
    "    df=test_df,\n",
    "    id_col=\"id\",\n",
    "    question_col=\"question\",\n",
    "    choices_col=\"choices\",\n",
    "    example_col=\"best_example\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/gpt-35-turbo_2023-08-06-13-12-27_results-98_example.json'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXAMPLE_RESULTS_SAVE_NAME = build_results_data_name(example_results_df, MODEL_NAME, \"example\")\n",
    "EXAMPLE_RESULTS_SAVE_PATH = os.path.join(DATA_DIR, EXAMPLE_RESULTS_SAVE_NAME)\n",
    "\n",
    "EXAMPLE_RESULTS_SAVE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to: ../data/gpt-35-turbo_2023-08-06-13-12-27_results-98_example.json\n"
     ]
    }
   ],
   "source": [
    "save_results_data_json(example_results_df, save_path=EXAMPLE_RESULTS_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_evaluator = Evaluator(\n",
    "    input_df=test_df,\n",
    "    predictions_df=example_results_df,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_k_majority_in_range</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>74</td>\n",
       "      <td>75.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>24.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   top_k_majority_in_range  count  percentage\n",
       "0                    False     74       75.51\n",
       "1                     True     24       24.49"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_in_range_counts = example_evaluator.get_in_range_prediction_counts(by_qtype=False)\n",
    "example_in_range_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qtype</th>\n",
       "      <th>top_k_majority_in_range</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mc</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>92.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mc</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>7.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t/f</td>\n",
       "      <td>False</td>\n",
       "      <td>61</td>\n",
       "      <td>72.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t/f</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "      <td>27.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qtype  top_k_majority_in_range  count  percentage\n",
       "0    mc                    False     13       92.86\n",
       "1    mc                     True      1        7.14\n",
       "2   t/f                    False     61       72.62\n",
       "3   t/f                     True     23       27.38"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_evaluator.get_in_range_prediction_counts(by_qtype=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/gpt-35-turbo_2023-08-06-13-14-22_evaluation-98_example.json'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXAMPLE_EVALUATION_SAVE_NAME = build_evaluation_data_name(example_results_df, MODEL_NAME, \"example\")\n",
    "EXAMPLE_EVALUATION_SAVE_PATH = os.path.join(DATA_DIR, EXAMPLE_EVALUATION_SAVE_NAME)\n",
    "\n",
    "EXAMPLE_EVALUATION_SAVE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved evaluation to: ../data/gpt-35-turbo_2023-08-06-13-14-22_evaluation-98_example.json\n"
     ]
    }
   ],
   "source": [
    "save_evaluation_data_json(example_in_range_counts, save_path=EXAMPLE_EVALUATION_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internal Context + Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextExampleForecasterTopK(ForecasterTopK):\n",
    "    def generate_example(self, question: str, choices: list[str], answer: str, context: str = None):\n",
    "        \"\"\"\n",
    "        Generates an example for the language model.\n",
    "\n",
    "        Args:\n",
    "            question (str): A question.\n",
    "            choices (list): A list of choices.\n",
    "            answer (str): An answer.\n",
    "            context (str): Context for the question.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of messages, consisting of a human message and an AI message.\n",
    "        \"\"\"\n",
    "        if context is None or context == \"\":\n",
    "            context = \"\"\n",
    "\n",
    "        vars = {\n",
    "            \"question\": question,\n",
    "            \"choices\": self.format_choices(choices),\n",
    "            \"context\": context\n",
    "        }\n",
    "\n",
    "        human_message = self.human_prompt.format_messages(**vars)[0]\n",
    "        \n",
    "        formatted_answer = self.yes_no_to_letter(answer)\n",
    "        ai_message = AIMessage(content=formatted_answer)\n",
    "\n",
    "        return [human_message, ai_message]\n",
    "\n",
    "    def get_llm_response_with_example(self, vars: dict, examples: list):\n",
    "        \"\"\"\n",
    "        Returns a response from the language model in the form of a dictionary\n",
    "        with the original prediction and the cleaned predicted answer.\n",
    "\n",
    "        Args:\n",
    "            vars (dict): A dictionary with the question and choices.\n",
    "            examples (list): A list of examples, consisting of user messages\n",
    "                and assistant messages.\n",
    "        \"\"\"\n",
    "\n",
    "        batch_messages = [\n",
    "            [self.system_prompt.format_messages()[0]] + \\\n",
    "            [AIMessage(content=\"Sure, I'd love to help!\")] + \\\n",
    "            examples + \\\n",
    "            [self.human_prompt.format_messages(**vars)[0]]\n",
    "        ]\n",
    "        result = self.chat.generate(batch_messages)\n",
    "\n",
    "        original_prediction = [generation.text for generation in result.generations[0]]\n",
    "\n",
    "        predicted_answers = [self.clean_answer(prediction) \n",
    "                             for prediction in original_prediction]\n",
    "        \n",
    "        return {\n",
    "            \"original_prediction\": original_prediction,\n",
    "            \"top_k_predicted_answers\": predicted_answers,\n",
    "            \"predicted_answer\": self.majority_choice(predicted_answers)\n",
    "        }\n",
    "    \n",
    "    def predict(self, question: str, choices: list[str], context: str, example: dict):\n",
    "        \"\"\"\n",
    "        Uses the language model to predict an answer to a question and returns\n",
    "        a dictionary with the question, choices, context, and predicted answer.\n",
    "\n",
    "        Args:\n",
    "            question (str): A question.\n",
    "            choices (list): A list of choices.\n",
    "            context (str): Context for the question.\n",
    "            example (dict): An example.\n",
    "        \"\"\"\n",
    "        vars = {\n",
    "            \"question\": question,\n",
    "            \"choices\": self.format_choices(choices),\n",
    "            \"context\": context\n",
    "        }\n",
    "\n",
    "        example_exchange = self.generate_example(\n",
    "            question=example[\"example_question\"],\n",
    "            choices=example[\"example_choices\"],\n",
    "            answer=example[\"example_answer\"],\n",
    "            context=example[\"example_context\"]\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            results = self.get_llm_response_with_example(vars, example_exchange)\n",
    "            original_prediction = results[\"original_prediction\"]\n",
    "            predicted_answer = results[\"predicted_answer\"]\n",
    "            predicted_answer_idx = self.idx_from_letter(predicted_answer)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            original_prediction = None\n",
    "            predicted_answer = None\n",
    "            predicted_answer_idx = None\n",
    "\n",
    "        if predicted_answer_idx is None or predicted_answer_idx >= len(choices):\n",
    "            predicted_answer = None\n",
    "            predicted_answer_text = None\n",
    "            predicted_answer_idx = None\n",
    "        else:\n",
    "            predicted_answer_text = choices[predicted_answer_idx]\n",
    "\n",
    "        response = {\n",
    "            \"question\": question,\n",
    "            \"choices\": choices,\n",
    "            \"original_prediction\": original_prediction,\n",
    "            \"predicted_answer\": predicted_answer,\n",
    "            \"predicted_answer_idx\": predicted_answer_idx,\n",
    "            \"predicted_answer_text\": predicted_answer_text,\n",
    "            \"top_k_predicted_answers\": results[\"top_k_predicted_answers\"]\n",
    "        }\n",
    "\n",
    "        return response\n",
    "    \n",
    "    def predict_df(self, df: pd.DataFrame, id_col: str, question_col: str, \n",
    "                   choices_col: str, context_col: str, example_col: str):\n",
    "        \"\"\"\n",
    "        Uses the language model to predict answers to a dataframe of questions.\n",
    "        Returns a dataframe with the question id, question, choices, and predicted answer.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): A dataframe of questions.\n",
    "            id_col (str): The name of the column containing the question IDs.\n",
    "            question_col (str): The name of the column containing the questions.\n",
    "            choices_col (str): The name of the column containing the choices.\n",
    "            context_col (str): The name of the column containing the context.\n",
    "            example_col (str): The name of the column containing the examples.\n",
    "        \"\"\"\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        for _, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "            question = row[question_col]\n",
    "            choices = row[choices_col]\n",
    "            context = row[context_col]\n",
    "            example = row[example_col]\n",
    "\n",
    "            error_count = 0\n",
    "            try:\n",
    "                prediction = self.predict(question, choices, context, example)\n",
    "            except Exception as e:\n",
    "                error_count += 1\n",
    "                print(f\"Error on question: {question}\")\n",
    "                print(f\"Error count: {error_count}\")\n",
    "                print(e)\n",
    "                continue\n",
    "\n",
    "            prediction[id_col] = row[id_col]\n",
    "            predictions.append(prediction)\n",
    "\n",
    "        predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "        return predictions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_example_chat = AzureChatOpenAI(\n",
    "    deployment_name=DEPLOYMENT_NAME,\n",
    "    model_name=MODEL_NAME,\n",
    "    model_kwargs={\n",
    "        \"top_p\": TOP_P_VALUE,\n",
    "    },\n",
    "    max_tokens=MAX_PREDICTION_TOKENS,\n",
    "    request_timeout=REQUEST_TIMEOUT,\n",
    ")\n",
    "\n",
    "context_example_forecaster = ContextExampleForecasterTopK(\n",
    "    chat=context_example_chat,\n",
    "    system_prompt=system_message_prompt,\n",
    "    human_prompt=human_context_message_prompt,\n",
    "    k=K_VALUE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample question: Will any country spend more on its military / defense in a given year before (and including) 2030 than the United States spends in the same year?\n",
      "\n",
      "Sample choices: ['yes', 'no']\n",
      "\n",
      "Sample context:\n",
      "Entities:\n",
      "- United States: a country in North America\n",
      "- Military/Defense: the government department responsible for the country's armed forces and their activities\n",
      "- Other countries: any other country in the world that has a military or defense budget\n",
      "\n",
      "Dates:\n",
      "- Before (and including) 2030: the time period before and up to the year 2030\n",
      "\n",
      "Locations:\n",
      "- North America: a continent that includes Canada, the United States, and Mexico\n",
      "- Other countries: any other country in the world\n",
      "\n",
      "Historical background:\n",
      "The United States has consistently been the world's largest military spender since the end of World War II. According to the Stockholm International Peace Research Institute (SIPRI), the US accounted for 38% of global military spending in 2020. The US spends more on its military than the next ten countries combined.\n",
      "\n",
      "Special terms:\n",
      "- Military spending: the amount of money a country allocates to its armed forces and their activities\n",
      "- Budget: an estimate of income and expenditure for a set period of time\n",
      "- Global military spending: the total amount of money spent on military by all countries in the world\n",
      "\n",
      "Rank of importance:\n",
      "1. United States\n",
      "2. Military/Defense\n",
      "3. Other countries\n",
      "4. Before (and including) 2030\n",
      "5. North America\n",
      "6. Global military spending\n",
      "7. Budget\n",
      "8. Military spending\n",
      "\n",
      "Sample best example:\n",
      "example_question: Will the U.S. enter a recession by July 1, 2019?\n",
      "example_choices: ['yes', 'no']\n",
      "example_answer: no\n",
      "majority_predicted_answer: A\n",
      "uncertainty: 0.0\n",
      "example_context: Entities:\n",
      "1. U.S. - Refers to the United States of America, a federal republic consisting of 50 states, a federal district, and various territories.\n",
      "2. Recession - A significant decline in economic activity, characterized by a decrease in gross domestic product (GDP), income, employment, industrial production, and sales.\n",
      "3. July 1, 2019 - Refers to a specific date.\n",
      "\n",
      "Definitions:\n",
      "1. U.S. - The United States is the world's largest economy by nominal GDP, with a highly diversified and technologically advanced economy.\n",
      "2. Recession - A recession is a business cycle contraction when there is a significant decline in economic activity lasting more than a few months, normally visible in real GDP, real income, employment, industrial production, and wholesale-retail sales. A recession is a period of declining economic performance across an entire economy, frequently defined as two consecutive quarters of GDP decline.\n",
      "3. July 1, 2019 - Refers to a specific date that has not yet occurred.\n",
      "\n",
      "Historical Background:\n",
      "1. U.S. - The United States has experienced numerous economic cycles throughout its history, including several recessions. The most recent recession occurred in 2008-2009, triggered by the subprime mortgage crisis and resulting in a global financial crisis.\n",
      "2. Recession - Economic recessions have occurred periodically throughout history, with some of the most notable ones being the Great Depression in the 1930s and the global financial crisis in 2008-2009.\n",
      "3. July 1, 2019 - Refers to a specific date that has not yet occurred.\n",
      "\n",
      "Important Economic/Societal Considerations:\n",
      "1. U.S. - The U.S. economy is highly diversified, with a significant portion of its GDP coming from the service sector. It is also heavily influenced by global economic conditions and policies, particularly those of China and the European Union.\n",
      "2. Recession - Recessions have significant impacts on the economy and society, including higher unemployment rates, decreased consumer and business spending, and decreased investment.\n",
      "3. July 1, 2019 - Refers to a specific date that has not yet occurred.\n",
      "\n",
      "Relationships:\n",
      "The U.S. economy is highly susceptible to economic cycles, including recessions. The occurrence of a recession would have significant impacts on the U.S. economy and society. The timing of a recession is difficult to predict, as it is influenced by a variety of economic and societal factors.\n",
      "\n",
      "Rank of Importance:\n",
      "1. Recession - The occurrence of a recession is the central focus of the question.\n",
      "2. U.S. - The U.S. economy is the subject of the question and is highly influential in the occurrence of a recession.\n",
      "3. July 1, 2019 - Refers to a specific date that is not particularly important to the question.\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 48\n",
    "sample_question = test_df.iloc[sample_idx][\"question\"]\n",
    "sample_choices = test_df.iloc[sample_idx][\"choices\"]\n",
    "sample_context = test_df.iloc[sample_idx][\"context\"]\n",
    "sample_answer = test_df.iloc[sample_idx][\"answer\"]\n",
    "sample_best_example = test_df.iloc[sample_idx][\"best_example\"]\n",
    "\n",
    "print(f\"Sample question: {sample_question}\\n\")\n",
    "print(f\"Sample choices: {sample_choices}\\n\")\n",
    "print(f\"Sample context:\\n{sample_context}\\n\")\n",
    "print(f\"Sample best example:\")\n",
    "for key, value in sample_best_example.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Will any country spend more on its military / defense in a given year before (and including) 2030 than the United States spends in the same year?',\n",
       " 'choices': ['yes', 'no'],\n",
       " 'original_prediction': ['B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B'],\n",
       " 'predicted_answer': 'B',\n",
       " 'predicted_answer_idx': 1,\n",
       " 'predicted_answer_text': 'no',\n",
       " 'top_k_predicted_answers': ['B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B']}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = context_example_forecaster.predict(\n",
    "    question=sample_question,\n",
    "    choices=sample_choices,\n",
    "    context=sample_context,\n",
    "    example=sample_best_example\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/98 [00:03<00:53,  1.73it/s]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 47%|████▋     | 46/98 [00:42<00:39,  1.33it/s]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 53%|█████▎    | 52/98 [00:58<01:02,  1.37s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 65%|██████▌   | 64/98 [01:17<00:25,  1.32it/s]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 80%|███████▉  | 78/98 [01:37<00:11,  1.71it/s]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 84%|████████▎ | 82/98 [01:51<00:29,  1.87s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      " 95%|█████████▍| 93/98 [02:10<00:04,  1.17it/s]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='capstone-openai.openai.azure.com', port=443): Read timed out. (read timeout=10.0).\n",
      "100%|██████████| 98/98 [02:25<00:00,  1.48s/it]\n"
     ]
    }
   ],
   "source": [
    "context_example_results_df = context_example_forecaster.predict_df(\n",
    "    df=test_df,\n",
    "    id_col=\"id\",\n",
    "    question_col=\"question\",\n",
    "    choices_col=\"choices\",\n",
    "    context_col=\"context\",\n",
    "    example_col=\"best_example\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/gpt-35-turbo_2023-08-06-13-16-54_results-98_context-example.json'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONTEXT_EXAMPLE_RESULTS_SAVE_NAME = build_results_data_name(context_example_results_df, MODEL_NAME, \"context-example\")\n",
    "CONTEXT_EXAMPLE_RESULTS_SAVE_PATH = os.path.join(DATA_DIR, CONTEXT_EXAMPLE_RESULTS_SAVE_NAME)\n",
    "\n",
    "CONTEXT_EXAMPLE_RESULTS_SAVE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to: ../data/gpt-35-turbo_2023-08-06-13-16-54_results-98_context-example.json\n"
     ]
    }
   ],
   "source": [
    "save_results_data_json(context_example_results_df, save_path=CONTEXT_EXAMPLE_RESULTS_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_example_evaluator = Evaluator(\n",
    "    input_df=test_df,\n",
    "    predictions_df=context_example_results_df,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_k_majority_in_range</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>70</td>\n",
       "      <td>71.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>28</td>\n",
       "      <td>28.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   top_k_majority_in_range  count  percentage\n",
       "0                    False     70       71.43\n",
       "1                     True     28       28.57"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_example_in_range_counts = context_example_evaluator.get_in_range_prediction_counts(by_qtype=False)\n",
    "context_example_in_range_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qtype</th>\n",
       "      <th>top_k_majority_in_range</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mc</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t/f</td>\n",
       "      <td>False</td>\n",
       "      <td>56</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t/f</td>\n",
       "      <td>True</td>\n",
       "      <td>28</td>\n",
       "      <td>33.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qtype  top_k_majority_in_range  count  percentage\n",
       "0    mc                    False     14      100.00\n",
       "1   t/f                    False     56       66.67\n",
       "2   t/f                     True     28       33.33"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_example_evaluator.get_in_range_prediction_counts(by_qtype=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/gpt-35-turbo_2023-08-06-13-16-54_evaluation-98_context-example.json'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONTEXT_EXAMPLE_EVALUATION_SAVE_NAME = build_evaluation_data_name(context_example_results_df, MODEL_NAME, \"context-example\")\n",
    "CONTEXT_EXAMPLE_EVALUATION_SAVE_PATH = os.path.join(DATA_DIR, CONTEXT_EXAMPLE_EVALUATION_SAVE_NAME)\n",
    "\n",
    "CONTEXT_EXAMPLE_EVALUATION_SAVE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved evaluation to: ../data/gpt-35-turbo_2023-08-06-13-16-54_evaluation-98_context-example.json\n"
     ]
    }
   ],
   "source": [
    "save_evaluation_data_json(context_example_in_range_counts, save_path=CONTEXT_EXAMPLE_EVALUATION_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_k_majority_in_range</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>71</td>\n",
       "      <td>72.45</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "      <td>27.55</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>71</td>\n",
       "      <td>72.45</td>\n",
       "      <td>context</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "      <td>27.55</td>\n",
       "      <td>context</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>74</td>\n",
       "      <td>75.51</td>\n",
       "      <td>example</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>24.49</td>\n",
       "      <td>example</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>70</td>\n",
       "      <td>71.43</td>\n",
       "      <td>context_example</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>28</td>\n",
       "      <td>28.57</td>\n",
       "      <td>context_example</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>68</td>\n",
       "      <td>69.39</td>\n",
       "      <td>external_context</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>30.61</td>\n",
       "      <td>external_context</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   top_k_majority_in_range  count  percentage             model\n",
       "0                    False     71       72.45          baseline\n",
       "1                     True     27       27.55          baseline\n",
       "0                    False     71       72.45           context\n",
       "1                     True     27       27.55           context\n",
       "0                    False     74       75.51           example\n",
       "1                     True     24       24.49           example\n",
       "0                    False     70       71.43   context_example\n",
       "1                     True     28       28.57   context_example\n",
       "0                    False     68       69.39  external_context\n",
       "1                     True     30       30.61  external_context"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge results counts with new column called \"model\"\n",
    "baseline_in_range_counts[\"model\"] = \"baseline\"\n",
    "context_in_range_counts[\"model\"] = \"context\"\n",
    "external_context_in_range_counts[\"model\"] = \"external_context\"\n",
    "example_in_range_counts[\"model\"] = \"example\"\n",
    "context_example_in_range_counts[\"model\"] = \"context_example\"\n",
    "\n",
    "# combine baseline and context counts\n",
    "combined_in_range_counts = pd.concat([\n",
    "    baseline_in_range_counts, \n",
    "    context_in_range_counts,\n",
    "    example_in_range_counts,\n",
    "    context_example_in_range_counts,\n",
    "    external_context_in_range_counts\n",
    "])\n",
    "\n",
    "combined_in_range_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot percentage of true results in combined_in_range_counts\n",
    "plt.figure(figsize=(4, 3))\n",
    "\n",
    "ax = sns.barplot(\n",
    "    x=\"top_k_majority_in_range\",\n",
    "    y=\"percentage\",\n",
    "    hue=\"model\",\n",
    "    data=combined_in_range_counts,\n",
    ")\n",
    "\n",
    "ax.set_title(\"Percentage of in range predictions\")\n",
    "\n",
    "ax.set_xlabel(\"Prediction is in range\")\n",
    "ax.set_ylabel(\"Percentage\")\n",
    "\n",
    "# move legend to right side\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.8))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_k_majority_in_range</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "      <td>27.55</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "      <td>27.55</td>\n",
       "      <td>context</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>24.49</td>\n",
       "      <td>example</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>28</td>\n",
       "      <td>28.57</td>\n",
       "      <td>context_example</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>30.61</td>\n",
       "      <td>external_context</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   top_k_majority_in_range  count  percentage             model\n",
       "1                     True     27       27.55          baseline\n",
       "1                     True     27       27.55           context\n",
       "1                     True     24       24.49           example\n",
       "1                     True     28       28.57   context_example\n",
       "1                     True     30       30.61  external_context"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_counts = combined_in_range_counts[combined_in_range_counts[\"top_k_majority_in_range\"]]\n",
    "true_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot percentage against model in true_counts using seaborn\n",
    "plt.figure(figsize=(4, 3))\n",
    "\n",
    "ax = sns.barplot(\n",
    "    x=\"model\", \n",
    "    y=\"percentage\", \n",
    "    data=true_counts,\n",
    ")\n",
    "\n",
    "ax.set_title(\"Pipeline performance\")\n",
    "ax.set_xlabel(\"Pipeline\")\n",
    "ax.set_ylabel(\"Percentage of in-range predictions\")\n",
    "\n",
    "# set x-tick labels to 45 degrees and align with tick\n",
    "for item in ax.get_xticklabels():\n",
    "    item.set_rotation(30)\n",
    "    item.set_ha(\"right\")\n",
    "\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
